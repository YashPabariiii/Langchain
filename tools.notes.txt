
## ðŸ“ LangChain Tool Calling â€“ Common Mistakes & Fixes (My Notes)

### 1ï¸âƒ£ `bind_tools` needs a **list**

âŒ `llm.bind_tools(tool)`
âœ… `llm.bind_tools([tool])`

---

### 2ï¸âƒ£ Donâ€™t hardcode variables in strings

âŒ `"Count words in {file_path}"`
âœ… `f"Count words in {file_path}"`

---

### 3ï¸âƒ£ `ainvoke()` must be awaited

âŒ `llm.ainvoke()` (without `await`)
âœ… Use `invoke()` **or** `await ainvoke()` inside `async`

---

### 4ï¸âƒ£ Donâ€™t double-wrap messages

âŒ `llm.invoke([messages])`
âœ… `llm.invoke(messages)`

---

### 5ï¸âƒ£ Tool invocation requires **dict args**

âŒ `tool.invoke(pdf_path)`
âœ… `tool.invoke({"file_path": pdf_path})`

---

### 6ï¸âƒ£ Tool â‰  Message

âŒ `messages.append(tool_result)`
âœ… Wrap output in `ToolMessage`

```python
ToolMessage(
  content=str(tool_result),
  tool_call_id=tool_call["id"]
)
```

---

### 7ï¸âƒ£ Always use `tool_call_id`

* Links tool result to tool request
* Mandatory for final LLM response

---

### 8ï¸âƒ£ LLM does NOT execute tools

**Flow to remember:**

```
HumanMessage
â†’ AIMessage (tool_calls)
â†’ ToolMessage
â†’ AIMessage (final answer)
```

---

### 9ï¸âƒ£ PDF errors are NOT LangChain issues

`PdfStreamError` = corrupted / malformed PDF
Handle with `try/except`

---

### ðŸ”‘ One-line takeaway

> **LLM decides, you execute. Tools are orchestration, not magic.**